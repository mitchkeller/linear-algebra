<?xml version='1.0' encoding='utf-8'?>
<!-- Chapters are enclosed with <chapter> tags. Use xml:id to -->
<!-- uniquely identify the chapter.  The @xmlns:xi attribute  -->
<!-- is needed if you use xi:include in this file             -->
<chapter xml:id="ch_vector_spaces" xmlns:xi="http://www.w3.org/2001/XInclude">

<!-- Change title when you have one: -->
  <title>Vector Spaces</title>
  <!-- If the chapter has sections, there may be an introduction -->
  <!-- before those sections. Note the <p> tags around content.  -->

  <!-- Sections can be written directly here, but it might help  -->
  <!-- with organization to include them as separate files.      -->
  <!-- That way it is easy to include the section in a different -->
  <!-- chapter later if you change your mind about the order.    -->
  <section>
    <title>Definitions</title>

    <p>Vector spaces are the primary objects that we study in linear
    algebra. Generally speaking, a vector space is a collection of
    objects (called vectors) that preserves linear relationships; that
    is, the objects work well under vector addition and scalar
    multiplication. As you will see shortly, vectors are not always
    going to be the column vectors we have seen so far or viewed geometrically as arrows from one point to another.</p>

    <definition>
      <statement>
	  <p>A <term>vector space</term>, <m>V</m>, is a nonempty set of objects called <term>vectors</term> with two operations called addition and scalar multiplication such that the following hold for all <m>\vec{u}, \vec{v}, \vec{w} \in V</m> and <m>c,d \in \mathbb{R}</m>:
	  <ol>
	    <li>If <m>\vec{u}, \vec{v} \in V</m>, then <m>\vec{u}+\vec{v}\in V</m>.</li>
<li> <m>\vec{u}+\vec{v}=\vec{v}+\vec{u}</m></li>
<li> <m>(\vec{u}+\vec{v})+\vec{w}=\vec{u}+(\vec{v}+\vec{w})</m></li>
<li> There exists a vector <m>\vec{0}_V</m> such that <m>\vec{v}+\vec{0}_V=\vec{v}</m>.</li>
<li> For each <m>\vec{u} \in V</m>, there is a vector <m>-\vec{u} \in V</m> such that <m>\vec{u} + (-\vec{u})=\vec{0}_V</m>.</li>
<li> If <m>\vec{u} \in V</m> and <m>c \in \mathbb{R}</m>, then <m>c\vec{u} \in V</m>.</li>
<li> <m>c(\vec{u}+\vec{v})=c\vec{u}+c\vec{v}</m></li>
<li> <m>(c+d)\vec{v}=c\vec{v}+d\vec{v}</m></li>
<li> <m>c(d\vec{v})=(cd)\vec{v}</m></li>
<li> <m>1 \vec{v}=\vec{v}</m></li>
	  </ol>
You can refer to these properties as
<ol>
<li> closure of vector addition</li>
<li> commutativity of vector addition</li>
<li> associativity of vector addition</li>
<li> existence of the zero vector</li>
<li> existence of the additive inverse</li>
<li> closure of scalar multiplication</li>
<li> distributive property of scalar multiplication across vector addition</li>
<li> distributive property of scalar addition across scalar multiplication (of a vector)</li>
<li> associativity of scalar multiplication</li>
<li> existence of scalar multiplicative identity</li>
</ol>
	  </p>
      </statement>
    </definition>

<p>This is the definition for a <em>real</em> vector space since the scalars come from <m>\mathbb{R}</m>, the real numbers. Sometimes it will be useful for us to consider complex vector spaces (scalars come from <m>\mathbb{C}</m>), but unless otherwise stated, you should assume that you are working with a real vector space.</p>

<investigation><introduction><p>
In order to gain an appreciation of definitions, use only the above definition to prove the following results:</p></introduction>
<task>
<statement><p>The zero vector is unique. You can begin this by supposing that there exists some <m>\vec{w}</m> such that <m>\vec{x} +\vec{w} = \vec{x}</m> for every <m>\vec{x} \in V</m>, then you need to show that <m>\vec{w}</m> must equal <m>\vec{0}_V</m>.</p></statement>
</task>
<task><statement><p>The additive inverse of a vector is
unique.</p></statement></task>
</investigation>

<example>
  <p>
The real numbers, <m>\mathbb{R}</m>, are a vector space since all of
the above properties hold.
  </p>
</example>
<example>
  <p>
Real valued vectors, <m>\mathbb{R}^n</m>, are a vector space since all
of the above properties hold when vector addition and scalar
multiplication are done componentwise. We can think of the vectors in
<m>\mathbb{R}^n</m> as a directed line segment (an arrow) or as a
point in <m>n</m>-dimensional space.
  </p>
</example>


<investigation><statement><p> Show why <m>\mathbb{Z}^n</m>, the set of vectors with <m>n</m> integer components is not a vector space.
</p></statement></investigation>

<investigation><statement><p> Is <m>\mathbb{C}^n</m> a real vector space? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is <m>\mathbb{R}^n</m> a complex vector space? Why or why not?
</p></statement></investigation>

<example><p>
The set of <m>m</m> by <m>n</m> matrices over the real numbers,
<m>M_{m \times n}(\mathbb{R})</m> or simply <m>M_{m \times n}</m>, is
a vector space since all of the above properties hold when
<q>vector</q> addition and scalar multiplication are done entry
wise. The quotes are around vector in the previous sentence because
you may not always think of matrices as being vectors but using the
properties from <xref ref="sec_matrix_ops" />, you can treat matrices as vectors in the general sense.</p></example>


<investigation xml:id="vse"><introduction><p>The set of polynomials
(in variable <m>t</m>) of degree at most <m>n</m> is denoted by
<m>\mathbb{P}_n</m>.</p>
</introduction>
<task>
  <statement>
    <p>
      Is <m>t^2-4t \in \mathbb{P}_2</m>?
    </p>
  </statement>
</task>
<task>
  <statement>
    <p>Is <m>3t^2+t \in \mathbb{P}_3</m>?
    </p>
  </statement>
</task>
<task>
  <statement>
    <p>
      Is <m>t^2-t+1 \in \mathbb{P}_1</m>?
    </p>
  </statement>
</task>
<task>
  <statement>
    <p>
      Write <m>\mathbb{P}_n</m> as a set using set builder notation. Be sure you have a statement that you can use to verify if an object is in your set or not.
    </p>
  </statement>
</task>
<task>
  <statement>
    <p> Prove that <m>\mathbb{P}_n</m> is a real vector space.</p>
  </statement>
</task>
</investigation>
<example><p>
The following sets are also vector spaces:
<ol>
<li> The set of all polynomials (in variable <m>t</m>) denoted <m>\mathbb{P}</m>.
</li>
<li> <m>F(S,\mathbb{R})</m>, the set of functions from a set <m>S</m> to the real numbers. We will take a closer look at this vector space in the next problem.</li>
<li> <m>\{\vec{0}\}</m>, the <term>trivial vector space</term>.</li>
</ol></p></example>

<investigation>
  <introduction>
    <p> We are going to take a look at the
vector space <m>V=F(\{a,b,c\},\mathbb{R})</m> to get used to our more
general way of thinking about vectors and vector spaces. You should
think of the vector space <m>V</m> as the set of functions with domain
<m>\{a,b,c\}</m> and codomain <m>\mathbb{R}</m>. In other words, we
are looking at the set of functions that only use <m>a</m>, <m>b</m>,
and <m>c</m> as inputs and have outputs of real numbers.
<ul>
  <li>Let <m>g_1</m> be the function that takes
<m>a</m>, <m>b</m>, and <m>c</m> to <m>3</m>, <m>-2</m>, and <m>0</m>
  respectively. </li>
  <li> Let <m>g_2</m> be the function that takes
<m>a</m>, <m>b</m>, and <m>c</m> to <m>-2</m>, <m>7</m>, and <m>1</m>
  respectively.</li>
  <li> Let <m>g_3</m> be the function that takes
<m>a</m>, <m>b</m>, and <m>c</m> to <m>1</m>, <m>1</m>, and <m>1</m>
  respectively.</li>
  <li> Let <m>g_4</m> be the function that takes
<m>a</m>, <m>b</m>, and <m>c</m> to <m>0</m>, <m>0</m>, and <m>0</m>
  respectively.</li>
</ul>
    </p>
  </introduction>
  <task>
    <statement>
      <p>
	<ol>
  <li> Fill in the blank: <m>g_2(b) =
  </m><fillin characters="2" /> </li>
  <li>Fill in the blank: <m>g_3(a) =</m><fillin characters="2" /></li>
  <li>Fill in the blank: <m>g_1(c) =</m><fillin characters="2" /></li>
	</ol>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Does it make
      sense to add the inputs of these functions? Explain.</p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Does it
      make sense to add the outputs of these functions? Explain.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Let
<m>g_5</m> be the function that takes <m>5</m>, <m>1</m>, and <m>0</m>
to <m>a</m>, <m>b</m>, and <m>c</m> respectively. Is <m>g_5 \in V</m>?
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Describe the function <m>g_1 +g_2</m>. In other words, give the
outputs for all possible inputs and write a sentence about how you
      built <m>g_1+g_2</m> in terms of <m>g_1</m> and <m>g_2</m>.</p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Describe the function <m>3 g_3</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>What function when added to
      <m>g_2</m> will give <m>g_4</m>? </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Can you write <m>g_1</m> as a
linear combination of the set <m>\{ g_2 , g_3 , g_4\}</m>? Explain why
      or why not.</p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
Can you write <m>g_4</m> as a linear combination of
the set <m>\{ g_2 , g_3 , g_1\}</m>? Explain why or why not. 
      </p>
    </statement>
  </task>
</investigation>

<investigation>
  <task>
    <statement>
      <p>
Write a sentence or two about what property makes a vector <m>\vec{v}
\in V</m> the zero vector for <m>V</m>, called <m>\vec{0}_V</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>What is the zero vector for the vector space <m>M_{m \times
      n}</m>? Remember to state your answer as an element of <m>M_{m
      \times n}</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>What is the zero vector for the vector space
      <m>\mathbb{P}_n</m>? Remember to state your answer as an element
      of <m>\mathbb{P}_n</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
 What is the zero vector for the vector space <m>\mathbb{P}</m>?
 Remember to state your answer as an element of <m>\mathbb{P}</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
What is the zero vector for the vector space
<m>F(\mathbb{R},\mathbb{R})</m>? Remember to state your answer as an
element of <m>F(\mathbb{R},\mathbb{R})</m>.
      </p>
    </statement>
  </task>
</investigation>
</section>
<section>
  <title>Subspaces</title>

<p>As <xref ref="vse" /> shows, it can be very tedious to prove that a set is indeed a vector space. A <term>subspace</term> of a vector space is a subset that is itself a vector space. Since most of the properties of the vector spaces we look at get inherited from some larger vector space, it is often easier to show that a set is a vector space by showing it is a subspace of the appropriate parent vector space.</p>

<theorem>
  <statement>
<p>A subset <m>H</m> of a vector space <m>V</m> is a subspace if and only if the following are true:
<ol marker="(a)">
<li> The zero vector of <m>V</m> is in <m>H</m>; <m>\vec{0}_V \in H</m>.</li>
<li> H is closed under vector addition; if <m>\vec{u}, \vec{v} \in H</m>, then <m>\vec{u}+\vec{v}\in H</m>.</li>
<li> H is closed under scalar multiplication; if <m>\vec{u} \in H</m>
and <m>c \in \mathbb{R}</m>, then <m>c\vec{u} \in H</m>.</li>
</ol>
</p>
  </statement>

<proof>
  <p>We first assume that <m>H</m> is a subspace of <m>V</m>. Item (a)
  of the theorem follows from axiom 4 of being a vector space. Item
  (b) of the theorem follows from axiom 1 of being a vector
  space. Item (c) of the theorem follows from axiom 6 of being a
  vector space.</p>

  <p>For the converse, we assume that <m>H\subseteq V</m> and the
  three items of the theorem satement are satisfied. We must verify
  the 10 vector space axioms:
  <ol marker ="1.">
    <li>This follows from item (b) of the theorem statement.</li>
    <li>Since <m>H\subseteq V</m> and this axiom holds for all
    elements of <m>V</m>, the axiom holds when restricted to elements of <m>H</m>.</li>
    <li>Since <m>H\subseteq V</m> and this axiom holds for all
    elements of <m>V</m>, the axiom holds when restricted to elements of <m>H</m>.</li>
    <li>This follows from item (a) of the theorem statement.</li>
    <li>This requires proof. Since <m>-1\in\mathbb{R}</m>, item (c) of
    the theorem statement tells us that for all <m>\vec{u}\in H</m>,
    <m>(-1)\vec{u}=-\vec{u}\in H</m>. Thus, this axiom is verified.</li>
    <li>This follows from item (c) of the theorem statement.</li>
    <li>Since <m>H\subseteq V</m> and this axiom holds for all
    elements of <m>V</m>, the axiom holds when restricted to elements of <m>H</m>.</li>
    <li>Since <m>H\subseteq V</m> and this axiom holds for all
    elements of <m>V</m>, the axiom holds when restricted to elements of <m>H</m>.</li>
    <li>Since <m>H\subseteq V</m> and this axiom holds for all
    elements of <m>V</m>, the axiom holds when restricted to elements of <m>H</m>.</li>
    <li>Since <m>H\subseteq V</m> and this axiom holds for all
    elements of <m>V</m>, the axiom holds when restricted to elements of <m>H</m>.</li>
    
  </ol></p>
</proof>
</theorem>

<p>This theorem is so useful because we can prove a set is a vector
space by checking only <em>three</em> properties instead of the
<em>ten</em> that are involved in the definition. The reason that we
do not need to check these other properties is that by using this
subspace, we already have proven the proper rules of arithmetic from
the parent space. Additionally, since we are using the same rules for
scalar multiplication and vector addition as the parent space, we
<em>must</em> also have the same scalars as the parent space.
</p>
<investigation><statement><p> Use the preceding theorem to prove that <m>\mathbb{P}_n</m> is a subspace of <m>\mathbb{P}</m>.
</p>
</statement></investigation>

<investigation><statement><p> Is <m>\mathbb{R}</m> a subspace of <m>\mathbb{C}</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is <m>\mathbb{R}^2</m> a subspace of <m>\mathbb{R}^3</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is the set of points on the plane given by <m>z=0</m> a subspace of <m>\mathbb{R}^3</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is the set of points on the plane given by <m>z=1</m> a subspace of <m>\mathbb{R}^3</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Draw a plot of the points in
<m>\mathbb{R}^2</m> given by <m>\{ \vec{x}=\colvec{x_1\\ x_2} \in
\mathbb{R}^2 \mid x_1 x_2 \geq 0\}</m>. Is <m>\{ \vec{x}=\colvec{x_1\\
x_2} \in \mathbb{R}^2 \mid x_1 x_2 \geq 0\}</m> a subspace of <m>\mathbb{R}^2</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is <m>Sym_{n \times n}</m>, the set of symmetric <m>n</m> by <m>n</m> matrices a subspace of <m>M_{n \times n}</m>? Why or why not?
</p></statement></investigation>


<investigation><statement><p> Prove or disprove: The set of odd
functions on <m>\mathbb{R}</m> (i.e., those for which <m>f(-t)=-f(t)</m> for every <m>t \in \mathbb{R}</m>) a subspace of <m>F(\mathbb{R},\mathbb{R})</m>.
</p></statement>
<solution>
  <p>The statement is true. We use Theorem 3.6 to prove this. First note that the function <m>Z(t)=0</m>
  is the zero vector for this vector space, as for any function
  <m>f\colon \mathbb{R}\to\mathbb{R}</m>, <m>(f+Z)(t) = f(t)+Z(t) =
  f(t)+0 = f(t)</m>. To see that <m>Z</m> is odd, we have <m>Z(-t)
= 0=-0=-Z(t)</m>. Now suppose that <m>f,g</m> are odd functions. We
have
<me>(f+g)(-t) = f(-t)+g(-t)=-f(t)+(-g(t))=-(f(t)+g(t))=-(f+g)(t)</me>,
verifying the second part of the theorem is satisfied. Finally, let
<m>c\in\mathbb{R}</m>. Now <m>(cf)(-t) =
c(f(-t))=c(-f(t))=-cf(t)=-(cf)(t)</m>. Thus, the set of odd functions
are a subspace of the vector space of functions from <m>\mathbb{R}</m>
to <m>\mathbb{R}</m>.
  </p>
</solution></investigation>

<theorem><statement><p> If <m>A</m> is a <m>m</m> by <m>n</m> matrix, the solution set to the homogeneous equation <m>A\vec{x}=\vec{0}</m> is a subspace of <m>\mathbb{R}^n</m>.
</p></statement></theorem>

<theorem><statement><p> If <m>H</m> and <m>K</m> are subspaces of some vector space <m>V</m>, then the set <m>H \cap K</m> is a subspace of <m>V</m> as well.
</p></statement></theorem>

<investigation><statement><p> Prove or Disprove: the set of <m>2</m> by <m>2</m> matrices with at least one zero entry is a subspace of <m>M_{2 \times 2}</m>.
</p></statement></investigation>

<investigation><statement><p> Prove or Disprove: the set of matrices of the form <m>\begin{bmatrix} a \amp b \\0 \amp -a \end{bmatrix}</m> is a subspace of <m>M_{2 \times 2}</m>.
</p></statement></investigation>

<investigation><statement><p> Prove or disprove: The set of quadratic polynomials of the form <m>at^2+b</m> is a subspace of the vector space of polynomials.
</p></statement></investigation>
</section>
<section>
  <title>Span</title>
  
<p>Recall that a <term>linear combination</term> of the set <m>\{\vec{v_1},..\vec{v_k} \}</m> is a vector of the form <me>\sum_{i=1}^k c_i \vec{v_i} = c_1 \vec{v_1} + c_2 \vec{v_2}+...+c_k \vec{v_k}</me>.
Note that some of the <m>c_i</m> may be zero. In other words, not every vector in a set needs to be part of a linear combination from that set.</p>

<investigation><statement><p> Find a way to  write
<m>\vec{b}=\colvec{2\\ 4}</m> as a linear combination of
<m>\vec{v_1}=\colvec{1\\ 1}</m> and <m>\vec{v_2}=\colvec{-1\\ 1}</m>
or explain why it is not possible to do so?</p>
</statement>
</investigation>
<exercise><statement><p> Repeat the previous problem for
<m>\vec{b}=\colvec{0\\ 0}</m>, <m>\vec{b}=\colvec{-1\\ 2}</m>, and
<m>\vec{b}=\colvec{2\\ 2}</m>.
</p>
</statement>
</exercise>
<investigation><statement><p> Can you write <m>2+4t</m> as a linear
combination of <m>1+t</m> and <m>-1+t</m>?
</p>
</statement>
</investigation>

<investigation><statement><p> Can you write <m>\begin{bmatrix} 2\amp 3 \\1\amp 1 \end{bmatrix}</m> as a linear combination of <m>\begin{bmatrix} 1\amp 1 \\0\amp 1 \end{bmatrix}</m> and <m>\begin{bmatrix} 1\amp 2 \\-1\amp 1 \end{bmatrix}</m>?
</p>
</statement>
</investigation>

<p>The <term>span</term> of a set of vectors <m>S</m>, denoted
<m>span(S)</m> is the set of <em>all</em> possible linear
combinations of <m>S</m>. A set <m>S</m> is said to <term>span or
generate a vector space</term> <m>V</m> if <m>span(S)=V</m>.
</p>


<investigation><statement><p> If <m>S=\left\{ \colvec{1\\ 1\\ 1},\colvec{1\\ -1\\ 1} \right\}</m>, is <m>\vec{b}=\colvec{3\\ 1\\ 3} \in span(S)</m>?
</p>
</statement>
</investigation>

<exercise><statement><p> If <m>S=\left\{ \colvec{1\\ 1\\
1},\colvec{1\\ -1\\ 1} \right\}</m>, is <m>\vec{b}=\colvec{1\\ 2\\ 3}
\in span(S)</m>?</p>
</statement>
</exercise>

<investigation><statement><p> If <m>S=\left\{ \colvec{1\\ 1\\ 1},\colvec{1\\ -1\\ 1} \right\}</m>, is <m>\vec{b}=\colvec{0\\ 0\\ 0} \in span(S)</m>?
</p>
</statement>
</investigation>

<investigation><statement><p> If <m>S=\left\{ \colvec{1\\ 1\\ 1},\colvec{1\\ -1\\ 1},\colvec{1\\ -1\\ -1} \right\}</m>, is <m>\vec{b}=\colvec{1\\ 2\\ 3} \in span(S)</m>?
</p>
</statement>
</investigation>

<investigation><statement><p> Is <m>1-t^2</m> in the span of <m>\{ 3, 4+t+t^2,5-t\}</m>?
</p>
</statement>
</investigation>


<exercise><statement><p> For what value(s) of <m>\alpha</m> and <m>\beta</m> is <m>\vec{p}=\colvec{\beta\\ -2\\ \alpha\\ -4}</m> a solution to <m>A \vec{x}=\vec{b}</m> if <m>A = \begin{bmatrix} 1\amp 5\amp -2\amp 0 \\ -3\amp 1\amp 9\amp -5 \\ 4\amp -8\amp -1\amp 7 \end{bmatrix}</m> and <m>\vec{b}=\colvec{-7\\ 9\\ 0}</m>?
</p>
</statement>
</exercise>

<investigation><statement><p> Is <m>\vec{b}=\colvec{-7\\ 9\\ 0}</m> in the span of the set of columns of <m>A = \begin{bmatrix} 1\amp 5\amp -2\amp 0 \\ -3\amp 1\amp 9\amp -5 \\ 4\amp -8\amp -1\amp 7 \end{bmatrix}</m>? If so, what are the coefficients?
</p>
</statement>
</investigation>

<theorem><statement><p>Let <m>V</m> be a vector space. If
<m>S=\{\vec{v_1},\vec{v_2},\dots,\vec{v_k}\}\subseteq V</m> is a set of <m>k</m> vectors from <m>V</m>, then <m>span(S)</m> is a subspace of <m>V</m>.
</p>
</statement>
</theorem>

<investigation><introduction><p> Find a finite set of vectors that generates each of the following vector spaces (be sure to show why your set works):
</p>
</introduction>
<task>
  <statement><p>
    <m>\mathbb{R}^3</m>
  </p>
  </statement>
</task>
<task>
  <statement><p>
    <m>\mathbb{P}_2</m>
  </p>
  </statement>
</task>
<task>
  <statement><p>
    <m>Sym_{n \times n}</m>
  </p>
  </statement>
</task>
</investigation>

<investigation><statement><p> Show that the set <m>\{
1+t,t+t^2,1+t^3,t+t^2+t^3 \}</m> spans all of <m>\mathbb{P}_3</m>.</p>
</statement>
<hint><p>Come up with a system of equations that you will need to
solve and use your theorems from earlier chapters.</p>
</hint>
</investigation>

<investigation><statement><p> Geometrically describe the span of <m>
\left\{ \colvec{2\\ 1\\ 4} \right\} </m>.</p>
</statement>
</investigation>

<investigation><statement><p> Geometrically describe the span of <m>
\left\{ \colvec{2\\ 1\\ 4} , \colvec{3\\ -1\\ 1} \right\} </m>.</p>
</statement>
</investigation>


<investigation><statement><p> Does the span of <m> \left\{ \colvec{2\\ 1\\ 4} , \colvec{3\\ -1\\ 1} \right\} </m> have to go through the origin?</p></statement></investigation>


<investigation><statement><p> Does the span of <m> \left\{
\vec{v_1},...,\vec{v_k} \right\} </m> where <m>\vec{v_i} \in
\mathbb{R}^n</m> have to go through the origin?</p>
</statement>
</investigation>
</section>
<section>
  <title>Linear Independence</title>
  
  <definition>
    <statement>
      <p>
A set of vectors <m>S</m> is <term>linearly independent</term> if the
only linear combination of elements of <m>S</m> that equals the zero vector is the trivial linear combination. In other words, <m>S</m> being a linear independent set implies that if <m>c_1\vec{v_1}+c_2\vec{v_2}+...+c_k \vec{v_k}=\vec{0}</m> where <m>\vec{v_i} \in S</m>, then all <m>c_i=0</m>.
      </p>

<p>A set of vectors <m>S</m> is <term>linearly dependent</term> if the
set is not linearly independent. More specifically, there exists a
solution to <m>c_1\vec{v_1}+c_2\vec{v_2}+...+c_k \vec{v_k}=\vec{0}</m>
where <m>\vec{v_i} \in S</m> and at least one of the <m>c_j \neq
0</m>.</p>
    </statement>
  </definition>

<investigation><statement><p> Is the set <m>\left\{ \colvec{1\\ -3\\
2} \right\}</m> linearly independent?
</p>
</statement>
</investigation>


<investigation><statement><p> Is the set <m>\left\{\colvec{2\\ 3\\ 0},
\colvec{-1\\ -1\\ 2} \right\}</m> linearly independent?
</p>
</statement>
</investigation>

<investigation><task><p>
Choose a vector <m>\vec{v}</m> so that the set <m>\left\{ \colvec{2\\
3\\ 0}, \colvec{-1\\ -1\\ 2} , \vec{v}  \right\} </m> is linearly
independent, where <m>\vec{v} \in \mathbb{R}^3</m>.</p>
</task>
<task><p>Is your choice of <m>\vec{v}</m> in <m> Span \left( \left\{
\colvec{2\\ 3\\ 0}, \colvec{-1\\ -1\\ 2} \right\} \right)</m>? Show
why or why not.</p>
</task>
</investigation>

<investigation><statement><p> Is <m>\{ 2+t^2, 1+t^2 \}</m> a linearly dependent set in <m>\mathbb{P}_2</m>?
</p>
</statement>
</investigation>

<exercise><statement><p> Is <m>\left\{ \begin{bmatrix} 1\amp 1\\0\amp
0 \end{bmatrix},\begin{bmatrix}0\amp 0\\ 1\amp 1
\end{bmatrix},\begin{bmatrix} 1\amp 0\\0\amp 1
\end{bmatrix},\begin{bmatrix} 0\amp 1\\1\amp 0 \end{bmatrix}
\right\}</m> a linearly independent set in <m>M_{2 \times 2}</m>?
</p>
</statement>
</exercise>

<exercise><statement><p> Prove that <m>\{ 1+t,t+t^2,1+t^2 \}</m> is
linearly independent.</p>
</statement>
</exercise>

<theorem><statement><p> If a set <m>S</m> of a vector space <m>V</m>
contains <m>\vec{0}_V</m>, then <m>S</m> is linearly dependent.</p>
</statement>
</theorem>


<investigation><statement><p> If <m>A</m> is a <m>m</m> by <m>n</m>
matrix, then the columns of A form a linearly independent set if and
only if <m>A</m> has <fillin characters="5" /> pivot
columns. Completely justify your response.</p>
</statement>
</investigation>

<theorem><statement><p>If <m>M=\{ \vec{v_1},\vec{v_2},...,\vec{v_n}\}</m> is linearly independent, then any subset of <m>M</m> is linearly independent.
</p>
</statement>
</theorem>

<investigation><statement><p> Prove or disprove: If <m>M=\{ \vec{v_1},\vec{v_2},...,\vec{v_n}\}</m> is linearly dependent, then any subset of <m>M</m> is linearly dependent.
</p>
</statement>
</investigation>

<theorem><statement><p>If <m>\vec{u}</m> is in the span of <m>S</m>, then <m>S \cup \{\vec{u}\}</m> is linearly dependent.
</p>
</statement>
</theorem>

<!-- TEST QUESTION
%<investigation><statement><p> Prove that if <m>S</m> is linearly independent and <m>S \bigcup \{\vec{u}\}</m> is linearly dependent, then <m>\vec{u}</m> is in the span of <m>S</m>.
%\eq
-->
<p>
The following two theorems are a wonderful summary of the difference between and the importance of linear dependence and linear independence.
</p>
<theorem><statement><p>If <m>S</m> is a linearly dependent set, then
any <m>\vec{w} \in span(S)</m> can be written as a linear combination
from <m>S</m> in more than one way.</p>
</statement>
</theorem>

<theorem xml:id="u"><statement><p>If <m>S</m> is a linearly
independent set, then any <m>\vec{w} \in span(S)</m> can be written as
a linear combination from <m>S</m> in only one way.</p>
</statement>
</theorem>
</section>

<section>
  <title>Linear Transformations</title>
  <subsection>
    <title>A Digression Into Functions</title>
    <p>In class, we have already seen this definition, but we state it
    here for reference:</p>
    <definition>
      <statement>
	<p>
	  Let <m>A</m> and <m>B</m> be sets. A <term>function</term>
	  <m>f</m> from <m>A</m> to <m>B</m> is a way of associating
	  to each element of <m>A</m> a unique element of
	  <m>B</m>. We use the notation
	  <m>f\colon A\to B</m> to denote that <m>f</m> is a function from
	  <m>A</m> to <m>B</m>. For <m>a\in A</m>, we denote that <m>f</m>
	  associates <m>a</m> with <m>\in B</m> as <m>f(a)=b</m> or as
	  <m>a\stackrel{f}{\mapsto} b</m>. We call <m>A</m> the
	  <term>domain</term> of <m>f</m> and <m>B</m> the
	  <term>codomain</term> of <m>f</m>. The <term>image</term> of
	  <m>f</m> is
	  <me>\mathrm{im}(f) = \{b\in B\colon \text{ there exists }a\in
	  A\text{ such that }f(a)=b\}</me>. Sometimes the image is
	  called the <term>range</term>.
	</p>
      </statement>
    </definition>

    <p>We now introduce two properties of functions that will be
    important in this course and your further study of mathematics. </p>

    <p>A function <m>f: C \rightarrow D</m> is <term>one-to-one</term>
    if <m>f(x)=f(y)</m> implies <m>x=y</m>. This means that
    each input gets sent to a different output by the function
    <m>f</m>. Alternately, you can say a on-to-one function does not
    map two different inputs to the same output. For functions that we
    can graph in the <m>xy</m>-plane, being one-to-one is the same as
    passing the <em>horizontal</em> line test. A one-to-one function
    is also called an <term>injection</term> or said to be <term>injective</term>.</p>
    <example>
      <p>Any linear function from <m>\mathbb{R}</m> to <m>\R</m> is
      one-to-one. Suppose <m>f(x)=ax+b</m> with <m>a\neq 0</m>. To prove that <m>f</m> is
      one-to-one, we assume that <m>f(x)=f(y)</m> and show that
      <m>x=y</m>:
      <md>
	<mrow>f(x) \amp = f(y)</mrow>
	<mrow>ax+b\amp = ay+b</mrow>
	<mrow>ax\amp =ay</mrow>
	<mrow>x\amp =y</mrow>
	</md>
	Note that we used <m>a\neq 0</m> to divide both sides by <m>a</m>.
      </p>

      <p>The domain is important when considering if a function is
      one-to-one. To see why, consider the function <m>f\colon \R\to
      \R</m> with rule <m>f(x)=x^2</m>. Since <m>f(-1)=1=f(1)</m> but
      <m>-1\neq 1</m>, we see that this function is not
      one-to-one. However, if we change the domain and consider
      <m>g\colon \R^+\to\R</m> defined on the positive real numbers
      <m>\R^+</m> given by the rule <m>g(x)=x^2</m>, we see that
      <m>g</m> is one-to-one.</p>
    </example>

    <p>A function <m>f:C \rightarrow D</m> is <term>onto</term> if for
    all <m>d\in D</m>, there exists <m>c\in C</m> such that
    <m>f(c)=d</m>. In other words, a map <m>f</m> is onto if the image
    of <m>f</m> is all of <m>D</m>. An onto function is also said to
    be <term>surjective</term> or a <term>surjection</term>.</p>

    <example>
      <p>To prove that a function is onto, we take an arbitary element
      of the codomain and find an element of the domain that the
      function maps to the element of the codomain. We generally do
      this by first doing calculations on scratch paper and then
      demonstrating that the element of the domain <q>works</q> as our
      proof. For instance, consider the linear function
      <m>f(x)=ax+b</m> from <m>\R</m> to <m>\R</m> with <m>a\neq
      0</m>. This function is onto. To prove this, let
      <m>d\in\R</m>. We will show that <m>f\left(\frac{d-b}{a}\right)
      =d</m>:
      <md>
	<mrow>f\left(\frac{d-b}{a}\right) \amp =
	a\left(\frac{d-b}{a}\right) +b </mrow>
	<mrow>\amp= (d-b)+b</mrow>
	<mrow>\amp = d</mrow>
      </md>. Since we have started with an arbitrary lement <m>d</m> of
      the codomain and found an element of the domain that is mapped
      to <m>d</m>, we have proved that <m>f</m> is onto.</p>

      <p>The codomain is essential to deciding if a function is
      onto. For instance, the function <m>x\mapsto x^2</m> (with
      domain <m>\R</m>) is not onto
      if the codomain is <m>\R</m>, as there is no real number that
      squares to <m>-1</m>. However, if we change the codomain to be
      all nonnegative real numbers, then the function is onto as it
      maps <m>\sqrt{d}</m> do <m>d</m> for all nonnegative real
      numbers <m>d</m>.</p>
    </example>
<investigation><introduction><p> For each of the functions from
<m>\mathbb{R}</m> to <m>\mathbb{R}</m> below state whether the
function is either 1-1 but not onto, onto but not 1-1, 1-1 and onto,
or not 1-1 and not onto.</p>
</introduction>
<task><p><m>f(x) =e^x</m></p></task>
<task><p><m>f(x) =x^2(1-x)</m></p></task>
<task><p><m>f(x) =\sin(x)</m></p></task>
<task><p><m>f(x) =x^3</m></p></task>
<conclusion>
  <p>For any property above that a function is missing, can you change
  the domain and/or codomain so that the function does have the property?</p>
</conclusion>
</investigation>
    
  </subsection>
  <subsection>
    <title>Functions on vector spaces</title>
<p>Linear transformations are the <q>nice</q> functions from a vector space to a vector space. In particular, linear transformations preserve the operations of scalar multiplication and vector addition.</p>
<definition>
  <statement>
    <p>
A function <m>T</m> from a vector space <m>V</m> to a vector space <m>W</m> is a <term>linear transformation</term> if for every <m>\vec{v_1},\vec{v_2} \in V</m> and <m>c \in \mathbb{R}</m>
<ul>
<li> <m>T(\vec{v_1}+\vec{v_2})=T(\vec{v_1})+T(\vec{v_2})</m></li>
<li> <m>T(c\vec{v_1})=c T(\vec{v_1})</m></li>
</ul>
    </p>
  </statement>
</definition>
<investigation><statement><p> Prove that the map <m>T: \mathbb{R}^n
\rightarrow \mathbb{R}^m</m> given by <m>T(\vec{x}) = A\vec{x}</m> is
linear, where <m>A</m> is an <m>m</m> by <m>n</m> real-valued matrix.
</p>
</statement>
</investigation>
<p>Eventually we will be able to state a lot of linear transformations
as a <term>matrix transformation</term> like in the problem above, but
we will not be able to do this in general.</p>

<investigation><statement><p> Prove that the map <m>T: \mathbb{P} \to \mathbb{P}</m> given by <m>T(f)=\dfrac{df}{dt}</m> is linear. You may use your calculus knowledge.
</p>
</statement>
</investigation>


<investigation><introduction><p> For each of the following functions,
determine if the function is a linear transformation. Remember to
justify your reasoning and answers.</p>
</introduction>
<task><p><m>f_1:\mathbb{P} \to \mathbb{R}</m> where <m>f_1(\vec{p})=</m> the degree of the polynomial <m>\vec{p}</m></p></task>
<task><p><m>f_2:\mathbb{P} \to \mathbb{R}</m> where <m>f_2(\vec{p})= \vec{p}(t=1)</m></p></task>
<task><p><m>f_3:\mathbb{R}^2 \to \mathbb{R}^3</m> where <m>f_3(\colvec{a\\ b})=\colvec{a+b\\ a-b\\ b+1}</m></p></task>
<task><p><m>f_4:\mathbb{R}^3 \to \mathbb{R}^2</m> where <m>f_4(\colvec{a\\ b\\ c})=\colvec{a+b\\ a-c}</m></p></task>
<task><p><m>f_5:\mathbb{R}^3 \to \mathbb{R}^2</m> where <m>f_5(\colvec{a\\ b\\ c})=\colvec{2\\ a+b\\ c^2}</m></p></task>
</investigation>

<theorem><statement><p>If <m>T\colon V\to W</m> is a linear transformation and a set of vectors <m>\{v_1,v_2,v_3\}</m> is linearly dependent, then the set <m>\{T(v_1),T(v_2),T(v_3)\}</m> is linearly dependent.
</p></statement></theorem>

<investigation><statement><p> Give a counterexample to the following
statement: If <m>T\colon V\to W</m> is a linear transformation and a set of vectors <m>\{v_1,v_2,v_3\}</m> is linearly independent, then the set <m>\{T(v_1),T(v_2),T(v_3)\}</m> is linearly independent.
</p>
</statement>
</investigation>

<theorem><statement><p>If <m>T</m> is a linear transformation from
<m>V</m> to <m>W</m>, then <m>T(\vec{0}_V)=\vec{0}_W</m>.</p>
</statement>
</theorem>

<investigation><introduction><p> If a linear transformation, <m>T</m>, sends the vector <m>\vec{e_1}=\colvec{1\\ 0}</m> to <m>\colvec{3\\ -1\\ 1}</m> and sends the vector <m>\vec{e_2}=\colvec{0\\ 1}</m> to <m>\colvec{1\\ 0\\ 2}</m>, find the following:
</p></introduction>
<task><p><m>T\left(\colvec{3\\ 0}\right)</m></p></task>
<task><p><m>T\left(\colvec{0\\ 5}\right)</m></p></task>
<task><p><m>T\left(\colvec{a\\ b}\right)</m></p></task>
</investigation>

<investigation><statement><p> Find a matrix <m>A</m> such that for the transformation in the previous problem <m>T(\vec{x})=A\vec{x}</m>.
</p>
</statement>
</investigation>

<definition><statement><p> If <m>T</m> is a linear transformation from <m>\mathbb{R}^n</m> to <m>\mathbb{R}^m</m>, then the <term>standard matrix presentation</term> of <m>T</m> is a <m>m</m> by <m>n</m> matrix <me>A=[T(\vec{e_1}) \quad T(\vec{e_2}) \quad ... \quad T(\vec{e_n}) ]</me>
where <m>\vec{e_i}</m> is the <term><m>i</m>-th elementary
vector</term> of <m>\R^n</m>. Note that <m>(\vec{e_i})_j =
\delta_{i,j}</m>, where <m>\delta</m> is the Dirac delta function
defined by <me>\delta_{i,j}=\left\{ \begin{array}{cc} 0 \amp  \mbox{if
}i\neq j\\ 1 \amp  \mbox{if } i = j \end{array} \right. </me>
</p>
</statement>
</definition>

<p>The vector <m>\vec{e_i}</m> can also be thought of as the <m>i</m>-th column of <m>Id_n</m>, the <m>n</m> by <m>n</m> identity matrix. Because of how we defined the standard matrix presentation, only transformations from <m>\mathbb{R}^n</m> to <m>\mathbb{R}^m</m> will have standard matrix presentations. In particular, the standard matrix presentation keeps track of where the standard basis vectors (<m>\vec{e_i}</m>) go under the transformation <m>T</m>.</p>

<exercise><statement><p>
Write out <m>\vec{e_1}</m>, <m>\vec{e_2}</m>, and <m>\vec{e_3}</m>
from <m>\mathbb{R}^3</m>. What is the result of multiplying
<m>\begin{bmatrix} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i
\end{bmatrix}</m> by <m>\vec{e_1}</m>? What about <m>\vec{e_2}</m>?
<m>\vec{e_3}</m>?</p>

<p>What would this mean for the following matrix product: <me>\begin{bmatrix} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i \end{bmatrix} \begin{bmatrix} \vec{e_1}\amp \vec{e_2}\amp \vec{e_3} \end{bmatrix}</me>
</p></statement>
</exercise>


<investigation><introduction><p> Determine the standard matrix presentation <m>A</m> for the following <m>T</m>:</p></introduction>
<task><p><m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> reflects points over the vertical axis</p></task>
<task><p><m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> rotates points clockwise by <m>\pi/2</m></p></task>
<task><p><m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> rotates points by
<m>\pi</m> and then flips points over the vertical axis</p></task>
</investigation>

<!--<investigation><statement><p>
Draw what the image of the picture below will look like after applying given the linear transformations. It may help to look at where <m>\colvec{1\\ 0}</m>, <m>\colvec{0\\ 1}</m>, and <m>\colvec{1\\ 1}</m> get mapped by <m>T</m>.
%\begin{center} \includegraphics{smiley.png} \end{center}
\begin{enumerate}
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> reflects points across the vertical axis
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> rotates points clockwise by <m>\pi/2</m> (around the origin)
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> where <m>T(\vec{x})=A\vec{x}</m> and <m>A=\begin{bmatrix}1 \amp  2 \\0\amp 1 \end{bmatrix}</m>
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> where <m>T(\vec{x})=A\vec{x}</m> and <m>A=\begin{bmatrix}3 \amp  0 \\0\amp 2 \end{bmatrix}</m>
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> where <m>T(\vec{x})=A\vec{x}</m> and <m>A=\begin{bmatrix}0 \amp  -1 \\1\amp 0 \end{bmatrix}</m>
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> where <m>T(\vec{x})=A\vec{x}</m> and <m>A=\begin{bmatrix}0 \amp  0 \\0\amp 1 \end{bmatrix}</m>
\end{enumerate}
\eq
-->

<exercise><introduction><p> If a linear transformation, <m>T</m>, sends the vector <m>\colvec{1\\ 1}</m> to <m>\colvec{-2\\ 2}</m> and sends the vector <m>\colvec{-1\\ 1}</m> to <m>\colvec{0\\ 2}</m>, find the following:</p></introduction>
<task><statement><p><m>T\left(\colvec{1\\
0}\right)</m></p></statement><hint><p>How can you write <m>\colvec{1\\
0}</m> as a linear combination of  <m>\colvec{1\\ 1}</m> and
<m>\colvec{-1\\ 1}</m>?</p>
</hint>
</task>
<task><p><m>T\left(\colvec{0\\ 1}\right)</m></p></task>
<task><p><m>T\left(\colvec{a\\ b}\right)</m></p></task>
<task><p>Find the standard matrix presentation for <m>T</m></p></task>
</exercise>

<theorem><statement><p>
Let <m>T_{\vec{0}}</m> be the function from <m>V</m> to <m>W</m> such that <m>T(\vec{x})=\vec{0}_W</m> for every <m>\vec{x} \in V</m>. Let <m>Id_V</m> be the identity map on <m>V</m>, <m>Id_V(\vec{x}) = \vec{x}</m> for every <m>\vec{x} \in V</m>.
<ol>
  <li>The function <m>T_{\vec{0}}</m> is a linear transformation.</li>
  <li>The function <m>Id_V</m>  is a linear transformation.</li>
</ol>
</p>
</statement>
</theorem>
<p>The <term>null space</term>, or <term>kernel</term>, of a linear transformation <m>T:V \rightarrow W</m> is the set of inputs that get mapped to the zero vector of <m>W</m>. That is <m>Null(T)=\{\vec{x}\in V \mid T(\vec{x}) = \vec{0_W}\}</m>.</p>

<investigation><statement><p> Is <m>\vec{b}=\colvec{0\\ 2\\ 1}</m> in the image of the linear transformation <m>T(\vec{x})=A\vec{x}</m> where <m>A= \begin{bmatrix} 1\amp 2 \\ 3 \amp  4\\0\amp 0 \end{bmatrix}</m>? Justify your answer without doing any matrix operations.</p></statement><hint><p>Write the corresponding matrix equation as a vector equation.</p></hint></investigation>

<exercise><statement><p> Let <m>A=\begin{bmatrix} 1\amp 2\amp 3
\\4\amp 5\amp 6 \end{bmatrix}</m>. Find the image and null space of <m>T</m> where <m>T(\vec{x}) =A \vec{x}</m>. Remember to state the image and null space so that the reader can most easily verify whether a vector is in the set or not.
</p></statement></exercise>

<investigation><introduction><p> Let <m>T</m> from <m>\mathbb{R}^2</m> to <m>\mathbb{P}_2</m> be given by <m>T \left( \colvec{a\\ b} \right) = a +(a+b)t+(a-b)t^2</m>.</p></introduction>
<task><p>Prove <m>T</m> is linear.</p></task>
<task><p>Compute the image of <m>T</m>.</p></task>
<task><p>Compute the null space of <m>T</m>.</p></task>
</investigation>

<investigation><introduction><p> Let <m>V</m> be the vector space of
polynomials in <m>x</m> and <m>y</m>.</p></introduction>
<task><p>Show the transformation <m>T</m> that maps <m>f</m> to <m>\dfrac{\partial f}{\partial x}</m> is a linear transformation.</p></task>
<task><p>Compute the null space of <m>T</m>.</p></task>
<task><p>Compute the range of <m>T</m>.</p></task>
</investigation>

<theorem xml:id="rnss"><statement><p>
If <m>T</m> is a linear transformation from <m>V</m> to
<m>W</m>, then <m>null(T)</m> is a subspace of <m>V</m>.
</p>
</statement>
</theorem>

<theorem xml:id="rnss2"><statement><p>
If <m>T</m> is a linear transformation from <m>V</m> to <m>W</m>, then
<m>\mathrm{im}(T)</m> is a subspace of <m>W</m>.
</p>
</statement>
</theorem>

<investigation><introduction><p> Let <m>T</m> from <m>\mathbb{R}^2</m> to <m>\mathbb{P}_2</m> be given by <m>T \left( \colvec{a\\ b} \right) = a +(a+b)t+(a-b)t^2</m>.</p></introduction>
<task><p>Is <m>T</m> one-to-one?</p></task>
<task><p>Is <m>T</m> onto?</p></task>
</investigation>

<investigation><statement><p> Give an example of a linear
transformation from <m>\mathbb{R}^2</m> to <m>\mathbb{R}^3</m> that is
one-to-one.
</p>
</statement></investigation>


<investigation><statement><p> Give an example of a linear transformation from <m>\mathbb{R}^2</m> to <m>\mathbb{R}^2</m> that is onto.
</p></statement></investigation>


<investigation><statement><p> Give an example of a linear transformation from <m>\mathbb{R}^3</m> to <m>\mathbb{R}^2</m> that is onto.
</p></statement></investigation>

<investigation><statement><p> If the set of columns of a <m>m</m> by <m>n</m> matrix <m>A</m> are linearly independent, does the set of columns of <m>A</m> span all of <m>\mathbb{R}^m</m>?
</p></statement></investigation>
<investigation><statement><p> If the set of columns of a <m>m</m> by <m>n</m> matrix <m>A</m> are linearly independent, is the image of <m>T(\vec{x})=A\vec{x}</m> all of <m>\mathbb{R}^m</m>?
</p></statement></investigation>

<theorem><statement><p>A linear transformation <m>T:V \rightarrow
W</m> is onto if and only if <m>\mathrm{im}(T)=W</m>.</p></statement></theorem>

<theorem><statement><p> For each linear transformation <m>T</m> from
<m>V</m> to <m>W</m>, <m>null(T)=\{ \vec{0} \}</m> if and only if
<m>T</m> is one-to-one.</p></statement></theorem>
</subsection>
</section>
<!--

\section{Applications}
\begin{annotation}
\endnote{This application section is meant to show how solution sets to linear systems of differential equations are a vector space (a subspace of the proper set of functions). Specifically, the differential equation can be thought of as a linear transformation, and thus the solutions to homogeneous differential equations can be found as the null space of the linear transformation. The parallel between solution sets of homogeneous/non-homogenous systems of differential and linear equations is also highlighted.}
\end{annotation}

\begin{definition}
Let <m>\mathcal{C}^n(\mathbb{R},\mathbb{R})</m>, or simply <m>\mathcal{C}^n</m> be the set of functions from <m>\mathbb{R}</m> to <m>\mathbb{R}</m> that are <m>n</m> times continuously differentiable.
\end{definition}
<investigation><statement><p> Let <m>a_1,a_2,a_3,a_4 \in \mathbb{R}</m>. A solution to the system of differential equations: <me>\dfrac{dx}{dt} = a_1 \enskip x(t)+a_2 \enskip y(t)</me> <me>\dfrac{dy}{dt} = a_3 \enskip x(t) +a_4 \enskip y(t) </me> is a choice of <m>x</m> and <m>y</m> as functions of <m>t</m> such that both differential equations are satisfied.
\be
\item If the pair of functions <m>(g(t),h(t))</m> is a solution to the system above, what does this imply about the derivatives of <m>g</m> and <m>h</m>? Be very specific.

The solution set to the given set of differential equations will be a subset of the ordered pairs of differentiable functions; specifically the solutions will be in the set <m>(\mathcal{C}^2)^2=\{ (x(t),y(t))|x,y \in \mathcal{C}^2\}</m>.

\item Prove that the set of solutions to the system above is a subspace of the vector space <m>(\mathcal{C}^2)^2</m>.
\item Consider the system of differential equations given by <me>\dfrac{dx}{dt} = a_1 \enskip x(t)+a_2 \enskip y(t)</me> <me>\dfrac{dy}{dt} = a_3 \enskip x(t) + 1  </me>
Is the set of solutions to this system a subspace of <m>(\mathcal{C}^2)^2</m>? Be sure to justify why or why not.
\item Consider the system of differential equations given by <me>\dfrac{dx}{dt} =  (x(t))^2 +a_2 \enskip y(t)</me> <me>\dfrac{dy}{dt} = a_3 \enskip x(t) + a_4 \enskip y(t)  </me>
Is the set of solutions to this system a subspace of <m>(\mathcal{C}^2)^2</m>? Be sure to justify why or why not.
\ee
\eq
The previous result is especially important in a differential equations class because finding the solution set of the system of differential equations can reduce to finding a few solutions that spans a large enough space.

<investigation><statement><p> \begin{enumerate}
\item Let <m>S</m> be the set of solutions to the differential equation <m>a\dfrac{d^2x}{dt^2}+b\dfrac{dx}{dt}+c x(t)= 0</m>. Prove that <m>S=\{f \in F(\mathbb{R},\mathbb{R}) | a\dfrac{d^2f}{dt^2}+b\dfrac{df}{dt}+c f(t)= 0 \}</m>  is a subspace of <m>F(\mathbb{R},\mathbb{R})</m>.
\item If <m>f_1(t)</m> and <m>f_2(t)</m> are solutions to the differential equation <m>a\dfrac{d^2x}{dt^2}+b\dfrac{dx}{dt}+c (x(t))= g(t)</m>, then prove that <m>f_1-f_2</m> is a solution to the homogeneous differential equation <m>a\dfrac{d^2x}{dt^2}+b\dfrac{dx}{dt}+c (x(t))= 0</m>.
\item Conclude that the solution set of the non-homogeneous differential equation is of the form <m>y(t)+s(t)</m>, where <m>y</m> is a solution to the nonhomogeneous differential equation and <m>s(t) \in S</m>, where <m>S</m> is the solution set to the homogeneous differential equation.
\end{enumerate}
\eq
The previous problem is analogous to your work on Question \ref{q7}.
<investigation><statement><p> \be
\item Show that the transformation <m>T</m> from <m>\mathcal{C}^2</m> to <m>\mathcal{C}^2</m> given by <m>T(f)=a\dfrac{d^2f}{dt^2}+b\dfrac{df}{dt}+c f(t)</m> is linear.
\item What is <m>Null(T)</m>?
\ee
\eq
-->
  <!-- One or more of the sections of a chapter might be exercises-->
  <!--<xi:include href="./ex_first.ptx"/>-->
</chapter>
