<?xml version='1.0' encoding='utf-8'?>
<!-- Chapters are enclosed with <chapter> tags. Use xml:id to -->
<!-- uniquely identify the chapter.  The @xmlns:xi attribute  -->
<!-- is needed if you use xi:include in this file             -->
<chapter xml:id="ch_vector_spaces" xmlns:xi="http://www.w3.org/2001/XInclude">

<!-- Change title when you have one: -->
  <title>Vector Spaces</title>
  <!-- If the chapter has sections, there may be an introduction -->
  <!-- before those sections. Note the <p> tags around content.  -->

  <!-- Sections can be written directly here, but it might help  -->
  <!-- with organization to include them as separate files.      -->
  <!-- That way it is easy to include the section in a different -->
  <!-- chapter later if you change your mind about the order.    -->
  <section>
    <title>Definitions</title>

    <p>Vector spaces are the primary objects that we study in linear
    algebra. Generally speaking, a vector space is a collection of
    objects (called vectors) that preserves linear relationships; that
    is, the objects work well under vector addition and scalar
    multiplication. As you will see shortly, vectors are not always
    going to be the column vectors we have seen so far or viewed geometrically as arrows from one point to another.</p>

    <definition>
      <statement>
	  <p>A <term>vector space</term>, <m>V</m>, is a nonempty set of objects called <term>vectors</term> with two operations called addition and scalar multiplication such that the following hold for all <m>\vec{u}, \vec{v}, \vec{w} \in V</m> and <m>c,d \in \mathbb{R}</m>:
	  <ol>
	    <li>If <m>\vec{u}, \vec{v} \in V</m>, then <m>\vec{u}+\vec{v}\in V</m>.</li>
<li> <m>\vec{u}+\vec{v}=\vec{v}+\vec{u}</m></li>
<li> <m>(\vec{u}+\vec{v})+\vec{w}=\vec{u}+(\vec{v}+\vec{w})</m></li>
<li> There exists a vector <m>\vec{0}_V</m> such that <m>\vec{v}+\vec{0}_V=\vec{v}</m>.</li>
<li> For each <m>\vec{u} \in V</m>, there is a vector <m>-\vec{u} \in V</m> such that <m>\vec{u} + (-\vec{u})=\vec{0}_V</m>.</li>
<li> If <m>\vec{u} \in V</m> and <m>c \in \mathbb{R}</m>, then <m>c\vec{u} \in V</m>.</li>
<li> <m>c(\vec{u}+\vec{v})=c\vec{u}+c\vec{v}</m></li>
<li> <m>(c+d)\vec{v}=c\vec{v}+d\vec{v}</m></li>
<li> <m>c(d\vec{v})=(cd)\vec{v}</m></li>
<li> <m>1 \vec{v}=\vec{v}</m></li>
	  </ol>
You can refer to these properties as
<ol>
<li> closure of vector addition</li>
<li> commutativity of vector addition</li>
<li> associativity of vector addition</li>
<li> existence of the zero vector</li>
<li> existence of the additive inverse</li>
<li> closure of scalar multiplication</li>
<li> distributive property of scalar multiplication across vector addition</li>
<li> distributive property of scalar addition across scalar multiplication (of a vector)</li>
<li> associativity of scalar multiplication</li>
<li> existence of scalar multiplicative identity</li>
</ol>
	  </p>
      </statement>
    </definition>

<p>This is the definition for a <em>real</em> vector space since the scalars come from <m>\mathbb{R}</m>, the real numbers. Sometimes it will be useful for us to consider complex vector spaces (scalars come from <m>\mathbb{C}</m>), but unless otherwise stated, you should assume that you are working with a real vector space.</p>

<investigation><introduction><p>
In order to gain an appreciation of definitions, use only the above definition to prove the following results:</p></introduction>
<task>
<statement><p>The zero vector is unique. You can begin this by supposing that there exists some <m>\vec{w}</m> such that <m>\vec{x} +\vec{w} = \vec{x}</m> for every <m>\vec{x} \in V</m>, then you need to show that <m>\vec{w}</m> must equal <m>\vec{0}_V</m>.</p></statement>
</task>
<task><statement><p>The additive inverse of a vector is
unique.</p></statement></task>
</investigation>

<example>
  <p>
The real numbers, <m>\mathbb{R}</m>, are a vector space since all of
the above properties hold.
  </p>
</example>
<example>
  <p>
Real valued vectors, <m>\mathbb{R}^n</m>, are a vector space since all
of the above properties hold when vector addition and scalar
multiplication are done componentwise. We can think of the vectors in
<m>\mathbb{R}^n</m> as a directed line segment (an arrow) or as a
point in <m>n</m>-dimensional space.
  </p>
</example>


<investigation><statement><p> Show why <m>\mathbb{Z}^n</m>, the set of vectors with <m>n</m> integer components is not a vector space.
</p></statement></investigation>

<investigation><statement><p> Is <m>\mathbb{C}^n</m> a real vector space? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is <m>\mathbb{R}^n</m> a complex vector space? Why or why not?
</p></statement></investigation>

<example><p>
The set of <m>m</m> by <m>n</m> matrices over the real numbers,
<m>M_{m \times n}(\mathbb{R})</m> or simply <m>M_{m \times n}</m>, is
a vector space since all of the above properties hold when
<q>vector</q> addition and scalar multiplication are done entry
wise. The quotes are around vector in the previous sentence because
you may not always think of matrices as being vectors but using the
properties from <xref ref="sec_matrix_ops" />, you can treat matrices as vectors in the general sense.</p></example>


<investigation xml:id="vse"><introduction><p>The set of polynomials
(in variable <m>t</m>) of degree at most <m>n</m> is denoted by
<m>\mathbb{P}_n</m>.</p>
</introduction>
<task>
  <statement>
    <p>
      Is <m>t^2-4t \in \mathbb{P}_2</m>?
    </p>
  </statement>
</task>
<task>
  <statement>
    <p>Is <m>3t^2+t \in \mathbb{P}_3</m>?
    </p>
  </statement>
</task>
<task>
  <statement>
    <p>
      Is <m>t^2-t+1 \in \mathbb{P}_1</m>?
    </p>
  </statement>
</task>
<task>
  <statement>
    <p>
      Write <m>\mathbb{P}_n</m> as a set using set builder notation. Be sure you have a statement that you can use to verify if an object is in your set or not.
    </p>
  </statement>
</task>
<task>
  <statement>
    <p> Prove that <m>\mathbb{P}_n</m> is a real vector space.</p>
  </statement>
</task>
</investigation>
<example><p>
The following sets are also vector spaces:
<ol>
<li> The set of all polynomials (in variable <m>t</m>) denoted <m>\mathbb{P}</m>.
</li>
<li> <m>F(S,\mathbb{R})</m>, the set of functions from a set <m>S</m> to the real numbers. We will take a closer look at this vector space in the next problem.</li>
<li> <m>\{\vec{0}\}</m>, the <term>trivial vector space</term>.</li>
</ol></p></example>

<investigation>
  <introduction>
    <p> We are going to take a look at the
vector space <m>V=F(\{a,b,c\},\mathbb{R})</m> to get used to our more
general way of thinking about vectors and vector spaces. You should
think of the vector space <m>V</m> as the set of functions with domain
<m>\{a,b,c\}</m> and codomain <m>\mathbb{R}</m>. In other words, we
are looking at the set of functions that only use <m>a</m>, <m>b</m>,
and <m>c</m> as inputs and have outputs of real numbers.
<ul>
  <li>Let <m>g_1</m> be the function that takes
<m>a</m>, <m>b</m>, and <m>c</m> to <m>3</m>, <m>-2</m>, and <m>0</m>
  respectively. </li>
  <li> Let <m>g_2</m> be the function that takes
<m>a</m>, <m>b</m>, and <m>c</m> to <m>-2</m>, <m>7</m>, and <m>1</m>
  respectively.</li>
  <li> Let <m>g_3</m> be the function that takes
<m>a</m>, <m>b</m>, and <m>c</m> to <m>1</m>, <m>1</m>, and <m>1</m>
  respectively.</li>
  <li> Let <m>g_4</m> be the function that takes
<m>a</m>, <m>b</m>, and <m>c</m> to <m>0</m>, <m>0</m>, and <m>0</m>
  respectively.</li>
</ul>
    </p>
  </introduction>
  <task>
    <statement>
      <p>
	<ol>
  <li> Fill in the blank: <m>g_2(b) =
  </m><fillin characters="2" /> </li>
  <li>Fill in the blank: <m>g_3(a) =</m><fillin characters="2" /></li>
  <li>Fill in the blank: <m>g_1(c) =</m><fillin characters="2" /></li>
	</ol>
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Does it make
      sense to add the inputs of these functions? Explain.</p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Does it
      make sense to add the outputs of these functions? Explain.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Let
<m>g_5</m> be the function that takes <m>5</m>, <m>1</m>, and <m>0</m>
to <m>a</m>, <m>b</m>, and <m>c</m> respectively. Is <m>g_5 \in V</m>?
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Describe the function <m>g_1 +g_2</m>. In other words, give the
outputs for all possible inputs and write a sentence about how you
      built <m>g_1+g_2</m> in terms of <m>g_1</m> and <m>g_2</m>.</p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Describe the function <m>3 g_3</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>What function when added to
      <m>g_2</m> will give <m>g_4</m>? </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>Can you write <m>g_1</m> as a
linear combination of the set <m>\{ g_2 , g_3 , g_4\}</m>? Explain why
      or why not.</p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
Can you write <m>g_4</m> as a linear combination of
the set <m>\{ g_2 , g_3 , g_1\}</m>? Explain why or why not. 
      </p>
    </statement>
  </task>
</investigation>

<investigation>
  <task>
    <statement>
      <p>
Write a sentence or two about what property makes a vector <m>\vec{v}
\in V</m> the zero vector for <m>V</m>, called <m>\vec{0}_V</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>What is the zero vector for the vector space <m>M_{m \times
      n}</m>? Remember to state your answer as an element of <m>M_{m
      \times n}</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>What is the zero vector for the vector space
      <m>\mathbb{P}_n</m>? Remember to state your answer as an element
      of <m>\mathbb{P}_n</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
 What is the zero vector for the vector space <m>\mathbb{P}</m>?
 Remember to state your answer as an element of <m>\mathbb{P}</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
What is the zero vector for the vector space
<m>F(\mathbb{R},\mathbb{R})</m>? Remember to state your answer as an
element of <m>F(\mathbb{R},\mathbb{R})</m>.
      </p>
    </statement>
  </task>
</investigation>
</section>
<section>
  <title>Subspaces</title>

<p>As <xref ref="vse" /> shows, it can be very tedious to prove that a set is indeed a vector space. A <term>subspace</term> of a vector space is a subset that is itself a vector space. Since most of the properties of the vector spaces we look at get inherited from some larger vector space, it is often easier to show that a set is a vector space by showing it is a subspace of the appropriate parent vector space.</p>

<theorem>
  <statement>
<p>A subset <m>H</m> of a vector space <m>V</m> is a subspace if and only if the following are true:
<ol marker="a">
<li> The zero vector of <m>V</m> is in <m>H</m>; <m>\vec{0}_V \in H</m>.</li>
<li> H is closed under vector addition; if <m>\vec{u}, \vec{v} \in H</m>, then <m>\vec{u}+\vec{v}\in H</m>.</li>
<li> H is closed under scalar multiplication; if <m>\vec{u} \in H</m>
and <m>c \in \mathbb{R}</m>, then <m>c\vec{u} \in H</m>.</li>
</ol>
</p>
  </statement>
</theorem>

<p>This theorem is so useful because we can prove a set is a vector
space by checking only <em>three</em> properties instead of the
<em>ten</em> that are involved in the definition. The reason that we
do not need to check these other properties is that by using this
subspace, we already have proven the proper rules of arithmetic from
the parent space. Additionally, since we are using the same rules for
scalar multiplication and vector addition as the parent space, we
<em>must</em> also have the same scalars as the parent space.
</p>
<investigation><statement><p> Use the preceding theorem to prove that <m>\mathbb{P}_n</m> is a subspace of <m>\mathbb{P}</m>.
</p>
</statement></investigation>

<investigation><statement><p> Is <m>\mathbb{R}</m> a subspace of <m>\mathbb{C}</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is <m>\mathbb{R}^2</m> a subspace of <m>\mathbb{R}^3</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is the set of points on the plane given by <m>z=0</m> a subspace of <m>\mathbb{R}^3</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is the set of points on the plane given by <m>z=1</m> a subspace of <m>\mathbb{R}^3</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Draw a plot of the points in <m>\mathbb{R}^2</m> given by <m>\{ \vec{x}=\colvec{2}{x_1}{x_2} \in \mathbb{R}^2 |x_1 x_2 \geq 0\}</m>. Is <m>\{ \vec{x}=\colvec{2}{x_1}{x_2} \in \mathbb{R}^2 |x_1 x_2 \geq 0\}</m> a subspace of <m>\mathbb{R}^2</m>? Why or why not?
</p></statement></investigation>

<investigation><statement><p> Is <m>Sym_{n \times n}</m>, the set of symmetric <m>n</m> by <m>n</m> matrices a subspace of <m>M_{n \times n}</m>? Why or why not?
</p></statement></investigation>


<investigation><statement><p> Prove or disprove: The set of odd
functions on <m>\mathbb{R}</m> (i.e., those for which <m>f(-t)=-f(t)</m> for every <m>t \in \mathbb{R}</m>) a subspace of <m>F(\mathbb{R},\mathbb{R})</m>.
</p></statement></investigation>

<theorem><statement><p> If <m>A</m> is a <m>m</m> by <m>n</m> matrix, the solution set to the homogeneous equation <m>A\vec{x}=\vec{0}</m> is a subspace of <m>\mathbb{R}^n</m>.
</p></statement></theorem>

<theorem><statement><p> If <m>H</m> and <m>K</m> are subspaces of some vector space <m>V</m>, then the set <m>H \cap K</m> is a subspace of <m>V</m> as well.
</p></statement></theorem>

<investigation><statement><p> Prove or Disprove: the set of <m>2</m> by <m>2</m> matrices with at least one zero entry is a subspace of <m>M_{2 \times 2}</m>.
</p></statement></investigation>

<investigation><statement><p> Prove or Disprove: the set of matrices of the form <m>\begin{bmatrix} a \amp b \\0 \amp -a \end{bmatrix}</m> is a subspace of <m>M_{2 \times 2}</m>.
</p></statement></investigation>

<investigation><statement><p> Prove or disprove: The set of quadratic polynomials of the form <m>at^2+b</m> is a subspace of the vector space of polynomials.
</p></statement></investigation>
</section>
<!--

\section{Span}
Recall that a <term>linear combination} of the set <m>\{\vec{v_1},..\vec{v_k} \}</m> is a vector of the form <me>\sum_{i=1}^k c_i \vec{v_i} = c_1 \vec{v_1} + c_2 \vec{v_2}+...+c_k \vec{v_k}</me>
Note that some of the <m>c_i</m> may be zero. In other words, not every vector in a set needs to be part of a linear combination from that set.

<investigation><statement><p> Can you write <m>\vec{b}=\colvec{2}{2}{4}</m> as a linear combination of <m>\vec{v_1}=\colvec{2}{1}{1}</m> and <m>\vec{v_2}=\colvec{2}{-1}{1}</m>? Remember that you need to justify your work on every problem.
\eq

<investigation><statement><p> Repeat the previous problem for <m>\vec{b}=\colvec{2}{0}{0}</m>, <m>\vec{b}=\colvec{2}{-1}{2}</m>, and <m>\vec{b}=\colvec{2}{2}{2}</m>.
\eq

<investigation><statement><p> Can you write <m>2+4t</m> as a linear combination of <m>1+t</m> and <m>-1+t</m>?
\eq

<investigation><statement><p> Can you write <m>\begin{bmatrix} 2\amp 3 \\1\amp 1 \end{bmatrix}</m> as a linear combination of <m>\begin{bmatrix} 1\amp 1 \\0\amp 1 \end{bmatrix}</m> and <m>\begin{bmatrix} 1\amp 2 \\-1\amp 1 \end{bmatrix}</m>?
\eq

The <term>span} of a set of vectors <m>S</m>, denoted <m>span(S)</m> is the set of \underline{all} possible linear combinations of <m>S</m>. A set <m>S</m> is said to <term>span or generate a vector space} <m>V</m> if <m>span(S)=V</m>.

<investigation><statement><p> If <m>S=\left\{ \colvec{3}{1}{1}{1},\colvec{3}{1}{-1}{1} \right\}</m>, is <m>\vec{b}=\colvec{3}{3}{1}{3} \in span(S)</m>?
\eq

<investigation><statement><p> If <m>S=\left\{ \colvec{3}{1}{1}{1},\colvec{3}{1}{-1}{1} \right\}</m>, is <m>\vec{b}=\colvec{3}{1}{2}{3} \in span(S)</m>?
\eq

<investigation><statement><p> If <m>S=\left\{ \colvec{3}{1}{1}{1},\colvec{3}{1}{-1}{1} \right\}</m>, is <m>\vec{b}=\colvec{3}{0}{0}{0} \in span(S)</m>?
\eq

<investigation><statement><p> If <m>S=\left\{ \colvec{3}{1}{1}{1},\colvec{3}{1}{-1}{1},\colvec{3}{1}{-1}{-1} \right\}</m>, is <m>\vec{b}=\colvec{3}{1}{2}{3} \in span(S)</m>?
\eq

<investigation><statement><p> Is <m>1-t^2</m> in the span of <m>\{ 3, 4+t+t^2,5-t\}</m>?
\eq

<investigation><statement><p> For what value(s) of <m>\alpha</m> and <m>\beta</m> is <m>\vec{p}=\colvec{4}{\beta}{-2}{\alpha}{-4}</m> a solution to <m>A \vec{x}=\vec{b}</m> if <m>A = \begin{bmatrix} 1\amp 5\amp -2\amp 0 \\ -3\amp 1\amp 9\amp -5 \\ 4\amp -8\amp -1\amp 7 \end{bmatrix}</m> and <m>\vec{b}=\colvec{3}{-7}{9}{0}</m>?
\eq

<investigation><statement><p> Is <m>\vec{b}=\colvec{3}{-7}{9}{0}</m> in the span of the set of columns of <m>A = \begin{bmatrix} 1\amp 5\amp -2\amp 0 \\ -3\amp 1\amp 9\amp -5 \\ 4\amp -8\amp -1\amp 7 \end{bmatrix}</m>? If so, what are the coefficients?
\eq

<investigation><statement><p> Prove that if <m>S</m> is a set of <m>k</m> vectors from a vector space <m>V</m>, then <m>span(S)</m> is a subspace of <m>V</m>.
\eq

<investigation><statement><p> Find a finite set of vectors that generates each of the following vector spaces (be sure to show why your set works):
\begin{enumerate}
\item <m>\mathbb{R}^3</m>
\item <m>\mathbb{P}_2</m>
\item <m>Sym_{n \times n}</m>
\end{enumerate}
\eq

<investigation><statement><p> Show that the set <m>\{ 1+t,t+t^2,1+t^3,t+t^2+t^3 \}</m> spans all of <m>\mathbb{P}_3</m>. Hint: Come up with a system of equations that you will need to solve and use your theorems from Chapter 1.
\eq


<investigation><statement><p> Geometrically describe the span of <m> \left\{ \colvec{3}{2}{1}{4} \right\} <m>.
\eq

<investigation><statement><p> Geometrically describe the span of <m> \left\{ \colvec{3}{2}{1}{4} , \colvec{3}{3}{-1}{1} \right\} <m>.
\eq

<investigation><statement><p> Does the span of <m> \left\{ \colvec{3}{2}{1}{4} , \colvec{3}{3}{-1}{1} \right\} <m> have to go through the origin?
\eq

<investigation><statement><p> Does the span of <m> \left\{ \vec{v_1},...,\vec{v_k} \right\} <m> where <m>\vec{v_i} \in \mathbb{R}^n</m> have to go through the\break origin?
\eq

\section{Linear Independence}
\begin{definition}
A set of vectors <m>S</m> is <term>linearly independent} if the only linear combination of the zero vector is the trivial linear combination. In other words, <m>S</m> being a linear independent set implies that if <m>c_1\vec{v_1}+c_2\vec{v_2}+...+c_k \vec{v_k}=\vec{0}</m> where <m>\vec{v_i} \in S</m>, then all <m>c_i=0</m>.

A set of vectors <m>S</m> is <term>linearly dependent} if the set is not linearly independent. More specifically, there exists a solution to <m>c_1\vec{v_1}+c_2\vec{v_2}+...+c_k \vec{v_k}=\vec{0}</m> where <m>\vec{v_i} \in S</m> and at least one of the <m>c_j \neq 0</m>.
\end{definition}

<investigation><statement><p> Is the set <m>\left\{ \colvec{3}{1}{-3}{2} \right\}</m> linearly independent?
\eq

<investigation><statement><p> Is the set <m>\left\{\colvec{3}{2}{3}{0}, \colvec{3}{-1}{-1}{2} \right\}</m> linearly independent?
\eq

<investigation><statement><p> \be
\item Choose a vector <m>\vec{v}</m> so that the set <m>\left\{ \colvec{3}{2}{3}{0}, \colvec{3}{-1}{-1}{2} , \vec{v}  \right\} <m> is linearly independent, where <m>\vec{v} \in \mathbb{R}^3</m>.
\item Is your choice of <m>\vec{v}</m> in <m> Span \left( \left\{ \colvec{3}{2}{3}{0}, \colvec{3}{-1}{-1}{2} \right\} \right)</m>? Show why or why not.
\ee \eq

<investigation><statement><p> Is <m>\{ 2+t^2, 1+t^2 \}</m> a linearly dependent set in <m>\mathbb{P}_2</m>?
\eq

<investigation><statement><p> Is <m>\left\{ \begin{bmatrix} 1\amp 1\\0\amp 0 \end{bmatrix},\begin{bmatrix}0\amp 0\\ 1\amp 1 \end{bmatrix},\begin{bmatrix} 1\amp 0\\0\amp 1 \end{bmatrix},\begin{bmatrix} 0\amp 1\\1\amp 0 \end{bmatrix} \right\}</m> a linearly independent set in <m>M_{2 \times 2}</m>?
\eq

<investigation><statement><p> Prove that <m>\{ 1+t,t+t^2,1+t^2 \}</m> is linearly independent.
\eq

<investigation><statement><p> Prove that if a set <m>S</m> of a vector space <m>V</m> contains <m>\vec{0}_V</m>, then <m>S</m> is linearly dependent.
\eq

<investigation><statement><p> If <m>A</m> is a <m>m</m> by <m>n</m> matrix, then the columns of A form a linearly independent set if and only if <m>A</m> has \underline{\hspace{0.5in}} pivot columns. Completely justify your response. \eq

<investigation><statement><p> Prove the following statement: If <m>M=\{ \vec{v_1},\vec{v_2},...,\vec{v_n}\}</m> is linearly independent, then any subset of <m>M</m> is linearly independent.
\eq

<investigation><statement><p> Prove or disprove: If <m>M=\{ \vec{v_1},\vec{v_2},...,\vec{v_n}\}</m> is linearly dependent, then any subset of <m>M</m> is linearly dependent.
\eq

<investigation><statement><p> Prove that if <m>\vec{u}</m> is in the span of <m>S</m>, then <m>S \bigcup \{\vec{u}\}</m> is linearly dependent.
\eq

%<investigation><statement><p> Prove that if <m>S</m> is linearly independent and <m>S \bigcup \{\vec{u}\}</m> is linearly dependent, then <m>\vec{u}</m> is in the span of <m>S</m>.
%\eq

The following two questions are a wonderful summary of the difference between and the importance of linear dependence and linear independence.

<investigation><statement><p> Prove that if <m>S</m> is a linearly dependent set, then any <m>\vec{w} \in span(S)</m> can be written as a linear combination from <m>S</m> in more than one way. \eq

<investigation><statement><p>\label{u} Prove that if <m>S</m> is a linearly independent set, then any <m>\vec{w} \in span(S)</m> can be written as a linear combination from <m>S</m> in only one way. \eq


\section{Linear Transformations}
Linear transformations are the “nice” functions from a vector space to a vector space. In particular, linear transformations preserve the operations of scalar multiplication and vector addition.
\begin{definition}
A function <m>T</m> from a vector space <m>V</m> to a vector space <m>W</m> is a <term>linear transformation} if for every <m>\vec{v_1},\vec{v_2} \in V</m> and <m>c \in \mathbb{R}</m>
\begin{itemize}
<li> <m>T(\vec{v_1}+\vec{v_2})=T(\vec{v_1})+T(\vec{v_2})</m>
<li> <m>T(c\vec{v_1})=c T(\vec{v_1})</m>
\end{itemize}
\end{definition}
<investigation><statement><p> Prove that the map <m>T: \mathbb{R}^n \rightarrow \mathbb{R}^m</m> given by <m>T(\vec{x}) = A\vec{x}</m> is linear, where <m>A</m> is an <m>m</m> by <m>n</m> real valued matrix.
\eq
Eventually we will be able to state a lot of linear transformations as a <term>matrix transformation} like in the problem above, but we will not be able to do this in general.
<investigation><statement><p> Prove that the map <m>T: \mathbb{P} \to \mathbb{P}</m> given by <m>T(f)=\dfrac{df}{dt}</m> is linear. You may use your calculus knowledge.
\eq

<investigation><statement><p> For each of the following functions, determine if the function is a linear transformation. Remember to justify your reasoning and answers.
\be
\item <m>f_1:\mathbb{P} \to \mathbb{R}</m> where <m>f_1(\vec{p})=</m> the degree of the polynomial <m>\vec{p}</m>
\item <m>f_2:\mathbb{P} \to \mathbb{R}</m> where <m>f_2(\vec{p})= \vec{p}(t=1)</m>
\item <m>f_3:\mathbb{R}^2 \to \mathbb{R}^3</m> where <m>f_3(\colvec{2}{a}{b})=\colvec{3}{a+b}{a-b}{b+1}</m>
\item <m>f_4:\mathbb{R}^3 \to \mathbb{R}^2</m> where <m>f_4(\colvec{3}{a}{b}{c})=\colvec{2}{a+b}{a-c}</m>
\item <m>f_5:\mathbb{R}^3 \to \mathbb{R}^2</m> where <m>f_5(\colvec{3}{a}{b}{c})=\colvec{2}{a+b}{c^2}</m>
\ee \eq

<investigation><statement><p> Prove that if <m>T</m> is a linear transformation and a set of vectors <m>\{v_1,v_2,v_3\}</m> is linearly dependent, then the set <m>\{T(v_1),T(v_2),T(v_3)\}</m> is linearly dependent.
\eq

<investigation><statement><p> Give a counterexample to the following statement: If <m>T</m> is a linear transformation and a set of vectors <m>\{v_1,v_2,v_3\}</m> is linearly independent, then the set <m>\{T(v_1),T(v_2),T(v_3)\}</m> is linearly independent.
\eq

<investigation><statement><p> Prove that if <m>T</m> is a linear transformation from <m>V</m> to <m>W</m>, then <m>T(\vec{0}_V)=\vec{0}_W</m>.
\begin{annotation}
\endnote{Sometimes students notice that they are using the fact that <m>0  \vec{v} = \vec{0}</m> for every <m>\vec{v} \in V</m>. If a student hasn't presented this idea yet, it can make a good class discussion to show why this works and have them write it up.}
\end{annotation}
\eq

<investigation><statement><p> If a linear transformation, <m>T</m>, sends the vector <m>\vec{e_1}=\colvec{2}{1}{0}</m> to <m>\colvec{3}{3}{-1}{1}</m> and sends the vector <m>\vec{e_2}=\colvec{2}{0}{1}</m> to <m>\colvec{3}{1}{0}{2}</m>, find the following:
\begin{itemize}
\item <m>T\left(\colvec{2}{3}{0}\right)</m>
\item <m>T\left(\colvec{2}{0}{5}\right)</m>
\item <m>T\left(\colvec{2}{a}{b}\right)</m>
\end{itemize}
\eq

<investigation><statement><p> Find a matrix <m>A</m> such that for the transformation in the previous problem <m>T(\vec{x})=A\vec{x}</m>.
\eq

\begin{definition} If <m>T</m> is a linear transformation from <m>\mathbb{R}^n</m> to <m>\mathbb{R}^m</m>, then the <term>standard matrix presentation} of <m>T</m> is a <m>m</m> by <m>n</m> matrix <me>A=[T(\vec{e_1}) \quad T(\vec{e_2}) \quad ... \quad T(\vec{e_n}) ]</me>
where <m>\vec{e_i}</m> is the <term></m>i</m>-th elementary vector} of \Rn. Note that <m>(\vec{e_i})_j = \delta_{i,j}</m>, where <m>\delta</m> is the Dirac delta function defined by <me>\delta_{i,j}=\left\{ \begin{array}{cc} 0 \amp  \mbox{if }i\neq j\\ 1 \amp  \mbox{if } i = j \end{array} \right. </me>
\end{definition}
The vector <m>\vec{e_i}</m> can also be thought of as the <m>i</m>-th column of <m>Id_n</m>, the <m>n</m> by <m>n</m> identity matrix. Because of how we defined the standard matrix presentation, only transformations from <m>\mathbb{R}^n</m> to <m>\mathbb{R}^m</m> will have standard matrix presentations. In particular, the standard matrix presentation keeps track of where the standard basis vectors (</m>\vec{e_i}</m>) go under the transformation <m>T</m>.

<investigation><statement><p>
Write out <m>\vec{e_1}</m>, <m>\vec{e_2}</m>, and <m>\vec{e_3}</m> from <m>\mathbb{R}^3</m>. What is the result of multiplying <m>\begin{bmatrix} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i \end{bmatrix}</m> by <m>\vec{e_1}</m>? What about <m>\vec{e_2}</m>? <m>\vec{e_3}</m>?

What would this mean for the following matrix product: <me>\begin{bmatrix} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i \end{bmatrix} \begin{bmatrix} \vec{e_1}\amp \vec{e_2}\amp \vec{e_3} \end{bmatrix}</me>
\eq

<investigation><statement><p> Determine the standard matrix presentation <m>A</m> for the following <m>T</m>:
\begin{itemize}
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> reflects points over the vertical axis
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> rotates points clockwise by <m>\pi/2</m>
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> rotates points by <m>\pi</m> and then flips points over the vertical axis
\end{itemize}
\eq

<investigation><statement><p>
Draw what the image of the picture below will look like after applying given the linear transformations. It may help to look at where <m>\colvec{2}{1}{0}</m>, <m>\colvec{2}{0}{1}</m>, and <m>\colvec{2}{1}{1}</m> get mapped by <m>T</m>.
%\begin{center} \includegraphics{smiley.png} \end{center}
\begin{enumerate}
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> reflects points across the vertical axis
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> rotates points clockwise by <m>\pi/2</m> (around the origin)
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> where <m>T(\vec{x})=A\vec{x}</m> and <m>A=\begin{bmatrix}1 \amp  2 \\0\amp 1 \end{bmatrix}</m>
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> where <m>T(\vec{x})=A\vec{x}</m> and <m>A=\begin{bmatrix}3 \amp  0 \\0\amp 2 \end{bmatrix}</m>
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> where <m>T(\vec{x})=A\vec{x}</m> and <m>A=\begin{bmatrix}0 \amp  -1 \\1\amp 0 \end{bmatrix}</m>
\item <m>T: \mathbb{R}^2 \to \mathbb{R}^2</m> where <m>T(\vec{x})=A\vec{x}</m> and <m>A=\begin{bmatrix}0 \amp  0 \\0\amp 1 \end{bmatrix}</m>
\end{enumerate}
\eq


<investigation><statement><p> If a linear transformation, <m>T</m>, sends the vector <m>\colvec{2}{1}{1}</m> to <m>\colvec{2}{-2}{2}</m> and sends the vector <m>\colvec{2}{-1}{1}</m> to <m>\colvec{2}{0}{2}</m>, find the following:
\begin{itemize}
\item <m>T\left(\colvec{2}{1}{0}\right)</m> Hint: How can you write <m>\colvec{2}{1}{0}</m> as a linear combination of  <m>\colvec{2}{1}{1}</m> and <m>\colvec{2}{-1}{1}</m>?
\item <m>T\left(\colvec{2}{0}{1}\right)</m>
\item <m>T\left(\colvec{2}{a}{b}\right)</m>
\item Find the standard matrix presentation for <m>T</m>
\end{itemize}
\eq

<investigation><statement><p>
Let <m>T_{\vec{0}}</m> be the function from <m>V</m> to <m>W</m> such that <m>T(\vec{x})=\vec{0}_W</m> for every <m>\vec{x} \in V</m>. Let <m>Id_V</m> be the identity map on <m>V</m>, <m>Id_V(\vec{x}) = \vec{x}</m> for every <m>\vec{x} \in V</m>.
\be
\item Prove that <m>T_{\vec{0}}</m> is linear.
\item Prove that <m>Id_V</m>  is linear.
\ee
\eq

The <term>range} of a linear transformation <m>T:V \rightarrow W</m> is the set of things in the codomain <m>W</m> that are the output of <m>T</m> for some input. That is <m>range(T)= \{\vec{y} \in W | \vec{y}=T(\vec{x}) \mbox{ for some } \vec{x} \in V\}</m>. The <term>null space}, or <term>kernel}, of a linear transformation <m>T:V \rightarrow W</m> is the set of inputs that get mapped to the zero vector of <m>W</m>. That is <m>Null(T)=\{\vec{x}\in V | T(\vec{x}) = \vec{0_W}\}</m>.

<investigation><statement><p> Is <m>\vec{b}=\colvec{3}{0}{2}{1}</m> in the range of the linear transformation <m>T(\vec{x})=A\vec{x}</m> where <m>A= \begin{bmatrix} 1\amp 2 \\ 3 \amp  4\\0\amp 0 \end{bmatrix}</m>? Justify your answer without doing any matrix operations. Hint: write the corresponding matrix equation as a vector equation.
\eq

<investigation><statement><p> Let <m>A=\begin{bmatrix} 1\amp 2\amp 3 \\4\amp 5\amp 6 \end{bmatrix}</m>. Find the range and null space of <m>T</m> where <m>T(\vec{x}) =A \vec{x}</m>. Remember to state the range and null space so that the reader can most easily verify whether a vector is in the set or not.
\eq

<investigation><statement><p> Let <m>T</m> from <m>\mathbb{R}^2</m> to <m>\mathbb{P}_2</m> be given by <m>T \left( \colvec{2}{a}{b} \right) = a +(a+b)t+(a-b)t^2</m>.
\begin{enumerate}
\item Prove <m>T</m> is linear.
\item Compute the range of <m>T</m>.
\item Compute the null space of <m>T</m>.
\end{enumerate}
\eq

<investigation><statement><p> Let <m>V</m> be the vector space of polynomials in <m>x</m> and <m>y</m>. \be \item Show the transformation <m>T</m> that maps <m>f</m> to <m>\dfrac{\partial f}{\partial x}</m> is a linear transformation.
\item Compute the null space of <m>T</m>.
\item Compute the range of <m>T</m>.
\ee
\eq

<investigation><statement><p>\label{rnss}
Let <m>T</m> be a linear transformation from <m>V</m> to <m>W</m>. Prove that <m>null(T)</m> is a subspace of <m>V</m>.
\eq
<investigation><statement><p>\label{rnss2}
Let <m>T</m> be a linear transformation from <m>V</m> to <m>W</m>. Prove that <m>range(T)</m> is a subspace of <m>W</m>.
\eq
A function <m>f: C \rightarrow D</m> is <term>one to one} if whenever <m>f(x)=f(y)</m>, then <m>x=y</m>. This means that each input gets sent to a different output by the function <m>f</m>. Alternately, you can say a one to one function does not map two different inputs to the same output.

A function <m>f:C \rightarrow D</m> is <term>onto} if every element of <m>D</m> has some input that is mapped to it. In other words, a map <m>f</m> is onto if the range of <m>f</m> is all of <m>D</m>.
<investigation><statement><p> For each of the functions from <m>\mathbb{R}</m> to <m>\mathbb{R}</m> below state whether the function is either 1-1 but not onto, onto but not 1-1, 1-1 and onto, or not 1-1 and not onto.
\begin{enumerate}
\item <m>f(x) =e^x</m>
\item <m>f(x) =x</m>
\item <m>f(x) =x^2</m>
\item <m>f(x) =1-x</m>
\item <m>f(x) =x^2(1-x)</m>
\item <m>f(x) =sin(x)</m>
\item <m>f(x) =x^3</m>
\end{enumerate}
\eq

<investigation><statement><p> Let <m>T</m> from <m>\mathbb{R}^2</m> to <m>\mathbb{P}_2</m> be given by <m>T \left( \colvec{2}{a}{b} \right) = a +(a+b)t+(a-b)t^2</m>.
\begin{enumerate}
\item Is <m>T</m> one-to-one?
\item Is <m>T</m> onto?
\end{enumerate}
\eq

<investigation><statement><p> Give an example of a linear transformation from <m>\mathbb{R}^2</m> to <m>\mathbb{R}^3</m> that is one to one.
\eq

<investigation><statement><p> Give an example of a linear transformation from <m>\mathbb{R}^2</m> to <m>\mathbb{R}^2</m> that is onto.
\eq


<investigation><statement><p> Give an example of a linear transformation from <m>\mathbb{R}^3</m> to <m>\mathbb{R}^2</m> that is onto.
\eq

<investigation><statement><p> If the set of columns of a <m>m</m> by <m>n</m> matrix <m>A</m> are linearly independent, does the set of columns of <m>A</m> span all of <m>\mathbb{R}^m</m>?
\eq
<investigation><statement><p> If the set of columns of a <m>m</m> by <m>n</m> matrix <m>A</m> are linearly independent, is the range of <m>T(\vec{x})=A\vec{x}</m> all of <m>\mathbb{R}^m</m>?
\eq

\begin{theorem} A linear transformation <m>T:V \rightarrow W</m> is onto iff <m>range(T)=W</m>. \end{theorem}

<investigation><statement><p> Prove that for <m>T</m> a linear transformation from <m>V</m> to <m>W</m>, \break <m>null(T)=\{ \vec{0} \}</m> iff <m>T</m> is 1-1.
\eq

\section{Applications}
\begin{annotation}
\endnote{This application section is meant to show how solution sets to linear systems of differential equations are a vector space (a subspace of the proper set of functions). Specifically, the differential equation can be thought of as a linear transformation, and thus the solutions to homogeneous differential equations can be found as the null space of the linear transformation. The parallel between solution sets of homogeneous/non-homogenous systems of differential and linear equations is also highlighted.}
\end{annotation}

\begin{definition}
Let <m>\mathcal{C}^n(\mathbb{R},\mathbb{R})</m>, or simply <m>\mathcal{C}^n</m> be the set of functions from <m>\mathbb{R}</m> to <m>\mathbb{R}</m> that are <m>n</m> times continuously differentiable.
\end{definition}
<investigation><statement><p> Let <m>a_1,a_2,a_3,a_4 \in \mathbb{R}</m>. A solution to the system of differential equations: <me>\dfrac{dx}{dt} = a_1 \enskip x(t)+a_2 \enskip y(t)</me> <me>\dfrac{dy}{dt} = a_3 \enskip x(t) +a_4 \enskip y(t) </me> is a choice of <m>x</m> and <m>y</m> as functions of <m>t</m> such that both differential equations are satisfied.
\be
\item If the pair of functions <m>(g(t),h(t))</m> is a solution to the system above, what does this imply about the derivatives of <m>g</m> and <m>h</m>? Be very specific.

The solution set to the given set of differential equations will be a subset of the ordered pairs of differentiable functions; specifically the solutions will be in the set <m>(\mathcal{C}^2)^2=\{ (x(t),y(t))|x,y \in \mathcal{C}^2\}</m>.

\item Prove that the set of solutions to the system above is a subspace of the vector space <m>(\mathcal{C}^2)^2</m>.
\item Consider the system of differential equations given by <me>\dfrac{dx}{dt} = a_1 \enskip x(t)+a_2 \enskip y(t)</me> <me>\dfrac{dy}{dt} = a_3 \enskip x(t) + 1  </me>
Is the set of solutions to this system a subspace of <m>(\mathcal{C}^2)^2</m>? Be sure to justify why or why not.
\item Consider the system of differential equations given by <me>\dfrac{dx}{dt} =  (x(t))^2 +a_2 \enskip y(t)</me> <me>\dfrac{dy}{dt} = a_3 \enskip x(t) + a_4 \enskip y(t)  </me>
Is the set of solutions to this system a subspace of <m>(\mathcal{C}^2)^2</m>? Be sure to justify why or why not.
\ee
\eq
The previous result is especially important in a differential equations class because finding the solution set of the system of differential equations can reduce to finding a few solutions that spans a large enough space.

<investigation><statement><p> \begin{enumerate}
\item Let <m>S</m> be the set of solutions to the differential equation <m>a\dfrac{d^2x}{dt^2}+b\dfrac{dx}{dt}+c x(t)= 0</m>. Prove that <m>S=\{f \in F(\mathbb{R},\mathbb{R}) | a\dfrac{d^2f}{dt^2}+b\dfrac{df}{dt}+c f(t)= 0 \}</m>  is a subspace of <m>F(\mathbb{R},\mathbb{R})</m>.
\item If <m>f_1(t)</m> and <m>f_2(t)</m> are solutions to the differential equation <m>a\dfrac{d^2x}{dt^2}+b\dfrac{dx}{dt}+c (x(t))= g(t)</m>, then prove that <m>f_1-f_2</m> is a solution to the homogeneous differential equation <m>a\dfrac{d^2x}{dt^2}+b\dfrac{dx}{dt}+c (x(t))= 0</m>.
\item Conclude that the solution set of the non-homogeneous differential equation is of the form <m>y(t)+s(t)</m>, where <m>y</m> is a solution to the nonhomogeneous differential equation and <m>s(t) \in S</m>, where <m>S</m> is the solution set to the homogeneous differential equation.
\end{enumerate}
\eq
The previous problem is analogous to your work on Question \ref{q7}.
<investigation><statement><p> \be
\item Show that the transformation <m>T</m> from <m>\mathcal{C}^2</m> to <m>\mathcal{C}^2</m> given by <m>T(f)=a\dfrac{d^2f}{dt^2}+b\dfrac{df}{dt}+c f(t)</m> is linear.
\item What is <m>Null(T)</m>?
\ee
\eq
-->
  <!-- One or more of the sections of a chapter might be exercises-->
  <!--<xi:include href="./ex_first.ptx"/>-->
</chapter>
